from datetime import datetime
import sys
import keras
import pandas as pd
import numpy as np
from tensorflow import keras
import matplotlib.pyplot as plt
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD
from tensorflow.keras import layers
from sklearn.utils import shuffle
from sklearn.preprocessing import StandardScaler


np.set_printoptions(threshold=sys.maxsize)
dataframe  = pd.read_csv("diamonds.csv", header=None ,sep=";")
dataset = dataframe.values
dataset = dataset[1:,:]
dataset = shuffle(dataset)
TrainDataset = dataset[501:,:]
TestDataset = dataset[:501,:]

x_train = TrainDataset[:,3:12]
y_train = TrainDataset[:,12]

x_test = TestDataset[1:,3:12]
y_test = TestDataset[1:,12]

sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

y_train = keras.utils.to_categorical(y_train, num_classes=5)
y_test = keras.utils.to_categorical(y_test, num_classes=5)

model = Sequential()
x_train=np.asarray(x_train).astype(np.float32)
x_test=np.asarray(x_test).astype(np.float32)
opt = keras.optimizers.Adam(learning_rate=0.0000025)
model = keras.Sequential()

model.add(layers.Dense(99, kernel_initializer='uniform', input_shape=(9,)))
model.add(layers.Dense(81, activation='relu'))
model.add(layers.Dense(63, activation='relu'))
model.add(layers.Dense(45, activation='relu'))
model.add(layers.Dense(5, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])
start = datetime.now()
history = model.fit(x_train, y_train,
          epochs=100,
          batch_size=100,
          verbose = 2,
          shuffle = True,
          use_multiprocessing=True
          )
end = datetime.now()
predict = model.predict_on_batch(x_test)
predict2 = model.predict(x_test, batch_size = 1)
np.set_printoptions(formatter={'float': lambda x: "{0:0.3f}".format(x)})
errors = 0
for i in range(len(predict2)):
    p=predict2[i].copy()
    if p[0]>p[1] and p[0]>p[2] and p[0]>p[3] and p[0]>p[4]:
        p[0]=1
        p[1]=0
        p[2]=0
        p[3]=0
        p[4]=0
    elif p[1]>p[0] and p[1]>p[2] and p[1]>p[3] and p[1]>p[4]:
        p[0]=0
        p[1]=1
        p[2]=0
        p[3]=0
        p[4]=0
    elif p[2]>p[0] and p[2]>p[1] and p[2]>p[3] and p[2]>p[4]:
        p[0]=0
        p[1]=0
        p[2]=1
        p[3]=0
        p[4]=0
    elif p[3]>p[0] and p[3]>p[1] and p[3]>p[2] and p[3]>p[4]:
        p[0]=0
        p[1]=0
        p[2]=0
        p[3]=1
        p[4]=0
    else:
        p[0]=0
        p[1]=0
        p[2]=0
        p[3]=0
        p[4]=1

    comparison = p == y_test[i]
    equal_arrays = comparison.all()

    if not equal_arrays:
        errors=errors+1
        print(i,". finalna predikcia = ", p, "skutocnost = ", y_test[i] , " predikcia = " , predict2[i] , " CHYBA")
    else:
        print(i,". finalna predikcia = ", p, "skutocnost = ", y_test[i] , " predikcia = " , predict2[i] , " USPECH")

print("pocet testovacich dat =", len(y_test) , ", pocet chyb =", errors , ", uspesnost =", (1-(errors/len(y_test)))*100 , "%" , "cas trenovania " , end-start)

plt.plot(history.history['accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train'], loc='lower right')
plt.show()